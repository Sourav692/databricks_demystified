{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8c985a3-ac64-4e78-a7f9-90847c8c2fef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Serve DeepSeek R1 (Distilled Llama 70B) using provisioned throughput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c619eb45-7f90-4144-a64a-fbc1d8e4b4bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This notebook demonstrates how to download and register the DeepSeek R1 distilled Llama model in Unity Catalog and deploy it using a Foundation Model APIs provisioned throughput endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "60faf022-abe5-425b-b929-2c3d797a8e44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Install the `transformers` library from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "943cb859-8a26-4dff-b8f0-d3ed648f9cf3",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Install HuggingFace transformers"
    }
   },
   "outputs": [],
   "source": [
    "!pip install transformers==4.44.2 mlflow\n",
    "%restart_python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "214b130a-71b3-4e29-ba94-a537a9621e9b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Download DeepSeek R1 distilled Llama 70B \n",
    "\n",
    "The following code downloads the DeepSeek R1 distilled Llama 70B model to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "593d862b-1d09-4ce4-904c-321210781e1d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"model_id\", \"deepseek-ai/DeepSeek-R1-Distill-Llama-70B\", \"Name of Huggingface Model\")\n",
    "\n",
    "model_id = dbutils.widgets.get(\"model_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d71d735-c5a6-4198-947d-6ffd2b809e85",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Set the huggingface cache folder on the local SSD drive."
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "LOCAL_DISK_HF = \"/local_disk0/hf_cache\"\n",
    "os.makedirs(LOCAL_DISK_HF, exist_ok=True)\n",
    "os.environ[\"HF_HOME\"] = LOCAL_DISK_HF\n",
    "os.environ[\"HF_DATASETS_CACHE\"] = LOCAL_DISK_HF\n",
    "os.environ[\"TRANSFORMERS_CACHE\"] = LOCAL_DISK_HF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b166f566-f78e-49a9-8d39-d8e6c571b89f",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Download first the checkpoint to deploy"
    }
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e50e415-857b-4a7b-9af5-a316e1c3ccb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Register the downloaded model to Unity Catalog\n",
    "\n",
    "The following code shows how to start and log a run that registers the downloaded model to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30d45bb3-9ae6-45e2-ae92-0f28488af9c0",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Register your downloaded model in Unity Catalog"
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import transformers\n",
    "\n",
    "my_uc_catalog = \"main\"\n",
    "my_uc_schema = \"msh\"\n",
    "uc_model_name = \"deepseek_r1_distilled_llama70b_v1\"\n",
    "\n",
    "task = \"llm/v1/chat\"\n",
    "model = transformers.AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "transformers_model = {\"model\": model, \"tokenizer\": tokenizer}\n",
    "\n",
    "with mlflow.start_run():\n",
    "    model_info = mlflow.transformers.log_model(\n",
    "        transformers_model=transformers_model,\n",
    "        artifact_path=\"model\",\n",
    "        task=task,\n",
    "        registered_model_name=f\"{my_uc_catalog}.{my_uc_schema}.{uc_model_name}\",\n",
    "        metadata={\n",
    "            \"task\": task,\n",
    "            \"pretrained_model_name\": \"meta-llama/Llama-3.3-70B-Instruct\",\n",
    "            \"databricks_model_family\": \"LlamaForCausalLM\",\n",
    "            \"databricks_model_size_parameters\": \"70b\",\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5d8018e-f41e-42bc-8a43-b7dd331d729e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Create a provisioned throughput endpoint for model serving\n",
    "\n",
    "The following code shows how to create a provisioned throughput model serving endpoint to serve the Llama 70B that you downloaded and registered to Unity Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fb6604a-196f-4a58-80e1-6eb5e1c05724",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.deployments import get_deploy_client\n",
    "\n",
    "\n",
    "client = get_deploy_client(\"databricks\")\n",
    "\n",
    "\n",
    "endpoint = client.create_endpoint(\n",
    "    name=uc_model_name,\n",
    "    config={\n",
    "        \"served_entities\": [{\n",
    "            \"entity_name\": f\"{my_uc_catalog}.{my_uc_schema}.{uc_model_name}\",\n",
    "            \"entity_version\": model_info.registered_model_version,\n",
    "             \"min_provisioned_throughput\": 0,\n",
    "             \"max_provisioned_throughput\": 9500,\n",
    "            \"scale_to_zero_enabled\": True\n",
    "        }],\n",
    "        \"traffic_config\": {\n",
    "            \"routes\": [{\n",
    "                \"served_model_name\": f\"{uc_model_name}-{model_info.registered_model_version}\",\n",
    "                \"traffic_percentage\": 100\n",
    "            }]\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "3. prov-throughput-deepseek-r1-distill-llama",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c90fce8c-119f-4b06-b438-b35beebfc516",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Provisioned Throughput GTE serving example\n",
    "\n",
    "\n",
    "Provisioned Throughput provides optimized inference for Foundation Models with performance guarantees for production workloads.\n",
    "\n",
    "This example walks through:\n",
    "\n",
    "- Downloading the model from Hugging Face transformers\n",
    "- Logging the model in a provisioned throughput supported format into the Databricks Unity Catalog or Workspace Registry\n",
    "- Enabling optimized serving on the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3bc7979-6e34-470d-b137-711fc36a960e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 1: Log the model for serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7737d0b2-323c-4641-9019-67d80fc05d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Update and install required dependencies\n",
    "!pip install -U mlflow\n",
    "!pip install -U transformers\n",
    "!pip install -U torch\n",
    "!pip install -U torchvision\n",
    "!pip install -U accelerate\n",
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d38ce0c-49cf-4e79-a704-ac6c1e4ccc04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "gte = \"Alibaba-NLP/gte-large-en-v1.5\"\n",
    "model = AutoModel.from_pretrained(gte, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(gte, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac1cf7f1-dc33-424f-b32f-ff79aa6e5515",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "To enable optimized serving, when logging the model, include the extra metadata dictionary when calling mlflow.transformers.log_model as shown below:\n",
    "\n",
    "metadata = {\"task\": \"llm/v1/completions\"}\n",
    "This specifies the API signature used for the model serving endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4fe1c0f6-6b5d-43ee-91b6-fe48186ad7fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import ColSpec, Schema, TensorSpec\n",
    "import numpy as np\n",
    "\n",
    "# Define the model input and output schema\n",
    "input_schema = Schema([ColSpec(type=\"string\", name=None)])\n",
    "output_schema = Schema([TensorSpec(type=np.dtype(\"float64\"), shape=(-1,))])\n",
    "\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "# Define an example input\n",
    "input_example = {\n",
    "    \"input\": np.array([\n",
    "        \"Welcome to Databricks!\"\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "66fdf097-6d1b-413f-89d8-c2787628d919",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import mlflow\n",
    "\n",
    "# Comment out the line below if not using Models in UC \n",
    "# and simply provide the model name instead of three-level namespace\n",
    "mlflow.set_registry_uri('databricks-uc')\n",
    "CATALOG = \"ml_demo\"\n",
    "SCHEMA = \"models\"\n",
    "registered_model_name = f\"{CATALOG}.{SCHEMA}.gte-large\"\n",
    "\n",
    "# Start a new MLflow run\n",
    "with mlflow.start_run():\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model=pipeline(\n",
    "            \"feature-extraction\",\n",
    "            model=model,\n",
    "            tokenizer=tokenizer\n",
    "        ),\n",
    "        artifact_path=\"gte-large\",\n",
    "        task=\"llm/v1/embeddings\",\n",
    "        metadata={\"task\": \"llm/v1/embeddings\"},\n",
    "        registered_model_name=registered_model_name\n",
    "   )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c9122833-eaf6-41d2-b11e-54d224d66726",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 2: View optimization information for your model\n",
    "\n",
    "Modify the cell below to change the model name. After calling the model optimization information API, you will be able to retrieve throughput chunk size information for your model. This is the number of tokens/second that corresponds to 1 throughput unit for your specific model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47cc3f41-be3a-48fc-addc-571e15817a6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Name of the registered MLflow model\n",
    "model_name = registered_model_name\n",
    "\n",
    "# Get the latest version of the MLflow model\n",
    "model_version = 1\n",
    "\n",
    "# Get the API endpoint and token for the current notebook context\n",
    "\n",
    "API_ROOT = \"https://e2-demo-field-eng.cloud.databricks.com/\"\n",
    "API_TOKEN = \"\"\n",
    "\n",
    "headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "response = requests.get(url=f\"{API_ROOT}/api/2.0/serving-endpoints/get-model-optimization-info/{model_name}/{model_version}\", headers=headers)\n",
    "\n",
    "if 'optimizable' not in response.json() or not response.json()['optimizable']:\n",
    "  raise ValueError(\"Model is not eligible for provisioned throughput\")\n",
    "\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53f33552-d3bd-4604-b34a-af52f6497242",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Step 3: Configure and create your model serving GPU endpoint\n",
    "Modify the cell below to change the endpoint name. After calling the create endpoint API, the logged MPT-7B model is automatically deployed with optimized LLM serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b1f097f6-ec0a-4b6b-b74b-df1091c0d5bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Set the name of the MLflow endpoint\n",
    "endpoint_name = \"gte-large_sb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "971740b0-1d79-428a-815c-784f75e78aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "chunk_size = response.json()['throughput_chunk_size']\n",
    "\n",
    "# Specify the minimum provisioned throughput \n",
    "min_provisioned_throughput = chunk_size*2\n",
    "\n",
    "# Specify the maximum provisioned throughput \n",
    "max_provisioned_throughput = chunk_size*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5cca9f30-223e-4351-bfd5-b5b2e637920d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"name\": endpoint_name,\n",
    "    \"config\": {\n",
    "        \"served_entities\": [\n",
    "            {\n",
    "                \"entity_name\": model_name,\n",
    "                \"entity_version\": model_version,\n",
    "                \"min_provisioned_throughput\": min_provisioned_throughput,\n",
    "                \"max_provisioned_throughput\": min_provisioned_throughput,\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}\n",
    "\n",
    "headers = {\"Context-Type\": \"text/json\", \"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
    "\n",
    "response = requests.post(url=f\"{API_ROOT}/api/2.0/serving-endpoints\", json=data, headers=headers)\n",
    "\n",
    "print(json.dumps(response.json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "90561c69-371b-4b14-8976-1c1484f696fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Step 4: Query your endpoint\n",
    "After your endpoint is ready, you can query it by making an API request. Depending on the model size and complexity, it can take 30 minutes or more for the endpoint to get ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d77d92f-afee-4528-bc0a-9ba73d5a6efb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ce7e573-2569-4469-b9a4-743ff4ab0180",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "API_ROOT = \"https://e2-demo-field-eng.cloud.databricks.com/\"\n",
    "API_TOKEN = \"\"\n",
    "data = {\n",
    "    \"input\": [\"Welcome to Databricks!\"]\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Context-Type\": \"text/json\",\n",
    "    \"Authorization\": f\"Bearer {API_TOKEN}\"\n",
    "}\n",
    "\n",
    "# Check whether the Endpoint is ready and sleep for 30second before next check\n",
    "while True:\n",
    "    state = requests.get(\n",
    "        url=f\"{API_ROOT}/api/2.0/serving-endpoints/{endpoint_name}\",\n",
    "        headers=headers\n",
    "    ).json()[\"state\"][\"ready\"]\n",
    "    if state == \"READY\":\n",
    "        print(\"Endpoint is ready to be queried\")\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(10)\n",
    "\n",
    "\n",
    "response = requests.post(\n",
    "    url=f\"{API_ROOT}/serving-endpoints/{endpoint_name}/invocations\",\n",
    "    json=data,\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "print(json.dumps(response.json()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b6c94795-4c90-4da5-98d0-ce03c5a45349",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "1. provisioned-throughput-gte-serving",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6d7611fa-9b92-4bf2-80d1-e6aa2d729331",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Get parameters from pipeline configuration with defaults\n",
    "# source_catalog = spark.conf.get(\"source_catalog\", \"main\")\n",
    "# source_schema = spark.conf.get(\"source_schema\", \"default\")\n",
    "\n",
    "# Build fully qualified source table names\n",
    "sales_source_table = f\"data_university.dlt01.demo_sales_source\"\n",
    "customers_source_table = f\"data_university.dlt01.demo_customers_source\"\n",
    "\n",
    "print(f\"Reading from: {sales_source_table}\")\n",
    "print(f\"Reading from: {customers_source_table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1675430-019b-41c3-a0f9-1597067ca118",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# BRONZE LAYER - Using Parameterized Source References\n",
    "# ===================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_sales\",\n",
    "    comment=f\"Streaming table from {sales_source_table}\"\n",
    ")\n",
    "def bronze_sales():\n",
    "    \"\"\"\n",
    "    Streaming table that reads from parameterized source.\n",
    "    The output will be created in the pipeline's target catalog.schema.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.readStream\n",
    "        .format(\"delta\")\n",
    "        .table(sales_source_table)\n",
    "    )\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"bronze_customers\", \n",
    "    comment=f\"Materialized view from {customers_source_table}\"\n",
    ")\n",
    "def bronze_customers():\n",
    "    \"\"\"\n",
    "    Materialized view reading from parameterized source.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.read\n",
    "        .format(\"delta\")\n",
    "        .table(customers_source_table)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b3227b3f-dd23-431d-a209-7b33a9707ca5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# SILVER LAYER - Using LIVE References\n",
    "# ===================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"silver_sales\",\n",
    "    comment=\"Enhanced sales data with business calculations\"\n",
    ")\n",
    "def silver_sales():\n",
    "    \"\"\"\n",
    "    Materialized view that transforms bronze data.\n",
    "    Uses LIVE keyword to reference other DLT tables.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.read.table(\"LIVE.bronze_sales\")\n",
    "        .withColumn(\"total_amount\", col(\"quantity\") * col(\"unit_price\"))\n",
    "        .withColumn(\"order_value_tier\", \n",
    "                   when(col(\"total_amount\") > 500, \"High\")\n",
    "                   .when(col(\"total_amount\") > 200, \"Medium\")\n",
    "                   .otherwise(\"Low\"))\n",
    "        .withColumn(\"year_month\", date_format(col(\"order_date\"), \"yyyy-MM\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f14b9737-a3b5-43c7-98b9-dd4998ea14b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# GOLD LAYER - Analytics and Aggregations\n",
    "# ===================================================================\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_sales_summary\",\n",
    "    comment=\"Product sales analytics by category\"\n",
    ")\n",
    "def gold_sales_summary():\n",
    "    \"\"\"\n",
    "    Gold layer aggregation for business intelligence.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        spark.read.table(\"LIVE.silver_sales\")\n",
    "        .groupBy(\"product_id\", \"product_name\", \"category\")\n",
    "        .agg(\n",
    "            sum(\"total_amount\").alias(\"total_revenue\"),\n",
    "            count(\"order_id\").alias(\"total_orders\"),\n",
    "            avg(\"total_amount\").alias(\"avg_order_value\")\n",
    "        )\n",
    "        .orderBy(desc(\"total_revenue\"))\n",
    "    )\n",
    "\n",
    "@dlt.table(\n",
    "    name=\"gold_customer_analytics\",\n",
    "    comment=\"Customer analysis with joined data\"\n",
    ")\n",
    "def gold_customer_analytics():\n",
    "    \"\"\"\n",
    "    Join customer and sales data for 360-degree view.\n",
    "    \"\"\"\n",
    "    sales_df = spark.read.table(\"LIVE.silver_sales\")\n",
    "    customers_df = spark.read.table(\"LIVE.bronze_customers\")\n",
    "    \n",
    "    return (\n",
    "        customers_df.join(\n",
    "            sales_df.groupBy(\"customer_id\").agg(\n",
    "                count(\"order_id\").alias(\"total_orders\"),\n",
    "                sum(\"total_amount\").alias(\"lifetime_value\"),\n",
    "                avg(\"total_amount\").alias(\"avg_order_value\")\n",
    "            ),\n",
    "            \"customer_id\",\n",
    "            \"left\"\n",
    "        )\n",
    "        .fillna(0, [\"total_orders\", \"lifetime_value\", \"avg_order_value\"])\n",
    "        .withColumn(\"customer_tier\",\n",
    "                   when(col(\"lifetime_value\") > 1000, \"Premium\")\n",
    "                   .when(col(\"lifetime_value\") > 500, \"Gold\")\n",
    "                   .otherwise(\"Standard\"))\n",
    "        .orderBy(desc(\"lifetime_value\"))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "395ea08d-c76e-452b-8963-956c1cfab32e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1. First DLT Pipeline - 2nd Set",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

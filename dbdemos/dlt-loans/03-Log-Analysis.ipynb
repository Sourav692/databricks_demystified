{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6fb69481-0841-430a-8ee5-4971daad2557",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "# DLT pipeline log analysis\n",
    "\n",
    "<img style=\"float:right\" width=\"500\" src=\"https://github.com/databricks-demos/dbdemos-resources/blob/main/images/product/dlt/dlt-loans-dashboard.png?raw=true\">\n",
    "\n",
    "Each DLT Pipeline can be configured to save out the metrics to a table in Unity Catalog. From this table we can see what is happening and the quality of the data passing through it.\n",
    "\n",
    "You can leverage the expecations directly as a SQL table with Databricks SQL to track your expectation metrics and send alerts as required. \n",
    "\n",
    "This notebook extracts and analyses expectation metrics to build such KPIS.\n",
    "\n",
    "## Your event log table is now available as a Table within your schema!\n",
    "\n",
    "This is simply set as an option in your DLT configuration menu.\n",
    "\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-engineering&org_id=3782931733495456&notebook=%2F03-Log-Analysis&demo_name=dlt-loans&event=VIEW&path=%2F_dbdemos%2Fdata-engineering%2Fdlt-loans%2F03-Log-Analysis&version=1&user_hash=f54348b201997908b91ace6288a9864114e7faea0de6a910579a7ab80989b7e0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "58940b98-cc3f-4e43-ade4-1ce1c40b6144",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": null
    }
   },
   "source": [
    "### A cluster has been created for this demo\n",
    "To run this demo, just select the cluster `dbdemos-dlt-loans-sourav_banerjee` from the dropdown menu ([open cluster configuration](https://dbc-3f5c1760-ce4f.cloud.databricks.com/#setting/clusters/0601-212506-muhm17p0/configuration)). <br />\n",
    "*Note: If the cluster was deleted after 30 days, you can re-create it with `dbdemos.create_cluster('dlt-loans')` or re-install the demo: `dbdemos.install('dlt-loans')`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a82a1b86-5e2f-4f96-baa3-b4d7546e8d25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "SELECT * FROM dbdemos.dbdemos_dlt_loan.event_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0b666fbd-d9d0-4b2a-9e32-34823308fe16",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Note: old legacy way to access your event log is through tthe event_log function:\n",
    "-- CREATE OR REPLACE TEMPORARY VIEW demo_dlt_loans_system_event_log_raw \n",
    "--   as SELECT * FROM event_log(TABLE(dbdemos.dbdemos_dlt_loan.raw_txs));\n",
    "-- SELECT * FROM demo_dlt_loans_system_event_log_raw order by timestamp desc;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2028d912-d928-4453-979b-4fb9c4da47b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "The `details` column contains metadata about each Event sent to the Event Log in a JSON blob. Using `parse_json` and the `VARIANT` data type we can explore it as if it was an object. There are different fields depending on what type of Event it is. Some examples include:\n",
    "* `user_action` Events occur when taking actions like creating the pipeline\n",
    "* `flow_definition` Events occur when a pipeline is deployed or updated and have lineage, schema, and execution plan information\n",
    "  * `output_dataset` and `input_datasets` - output table/view and its upstream table(s)/view(s)\n",
    "  * `flow_type` - whether this is a complete or append flow\n",
    "  * `explain_text` - the Spark explain plan\n",
    "* `flow_progress` Events occur when a data flow starts running or finishes processing a batch of data\n",
    "  * `metrics` - currently contains `num_output_rows`\n",
    "  * `data_quality` - contains an array of the results of the data quality rules for this particular dataset\n",
    "    * `dropped_records`\n",
    "    * `expectations`\n",
    "      * `name`, `dataset`, `passed_records`, `failed_records`\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14569f2b-e462-485c-abe7-03bf27db9d30",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Lineage Information"
    }
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "  details:flow_definition.output_dataset,\n",
    "  details:flow_definition.input_datasets,\n",
    "  details:flow_definition.flow_type,\n",
    "  details:flow_definition.schema,\n",
    "  details:flow_definition\n",
    "FROM dbdemos.dbdemos_dlt_loan.event_logs\n",
    "WHERE details:flow_definition IS NOT NULL\n",
    "ORDER BY timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d73602ea-f039-4136-9916-ca03ec611718",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Data Quality Results"
    }
   },
   "outputs": [],
   "source": [
    "select\n",
    "  e.origin.update_id,\n",
    "  ex.value:name::string,\n",
    "  ex.value:dataset::string,\n",
    "  ex.value:passed_records::long as passed_records,\n",
    "  ex.value:failed_records::long as failed_records\n",
    "from\n",
    "  dbdemos.dbdemos_dlt_loan.event_logs e,\n",
    "  lateral variant_explode(parse_json(e.details:flow_progress:data_quality:expectations:[ * ])) as ex\n",
    "where\n",
    "  e.event_type = \"flow_progress\"\n",
    "  and details:flow_progress:status = \"RUNNING\"\n",
    "  and details:flow_progress:data_quality:expectations IS NOT NULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f99215cb-8ef3-4eb9-8883-f418d0d2cdd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Your expectations are ready to be queried in SQL! Open the <a dbdemos-dashboard-id=\"dlt-expectations\" href='/sql/dashboardsv3/01f03f2ee4bb1cb9be3ce8b69670e763' target=\"_blank\">data Quality Dashboard example</a> for more details."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "03-Log-Analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

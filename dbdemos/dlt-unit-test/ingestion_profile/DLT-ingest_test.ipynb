{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "83996549-6fd4-427a-98f3-626be21f6aa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Defining the Test source\n",
    "\n",
    "## Adding an abstraction layer for testability \n",
    "\n",
    "By defining the ingestion source in an external table, we can easily switch from the production source to a test one.\n",
    "\n",
    "This lets you easily replace an ingestion from a Kafka server in production by a small csv file in your test. \n",
    "\n",
    "This notebook correspond to the TEST stream (the **blue** input source on the left)\n",
    "\n",
    "<img width=\"1000px\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/product_demos/dlt-advanecd/DLT-advanced-unit-test-1.png\"/>\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-engineering&org_id=3782931733495456&notebook=%2Fingestion_profile%2FDLT-ingest_test&demo_name=dlt-unit-test&event=VIEW&path=%2F_dbdemos%2Fdata-engineering%2Fdlt-unit-test%2Fingestion_profile%2FDLT-ingest_test&version=1&user_hash=f54348b201997908b91ace6288a9864114e7faea0de6a910579a7ab80989b7e0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "37cca495-e76e-45df-bc45-e6249764364a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Test Source for customer dataset\n",
    "\n",
    "\n",
    "This notebook will be used in test only. We'll generate a fixed test dataset and use this test data for our unit tests.\n",
    "\n",
    "Note that we'll have to run the test pipeline with a full refresh to reconsume all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8019d7ee-3e7a-4b5d-80e4-f473e2be844c",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest raw User stream data in incremental mode"
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "spark.conf.set(\"pipelines.incompatibleViewCheck.enabled\", \"false\")\n",
    "@dlt.view(comment=\"Raw user data - Test\")\n",
    "def raw_user_data():\n",
    "  return (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "      .option(\"cloudFiles.format\", \"json\")\n",
    "      .option(\"cloudFiles.schemaHints\", \"id int\")\n",
    "      .load(f\"/Volumes/dbdemos/dbdemos_dlt_unit_test/raw_data/test/users_json/*.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2836c43b-95cf-4807-9785-f32ed69d0859",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Ingest user spending score"
    }
   },
   "outputs": [],
   "source": [
    "@dlt.view(comment=\"Raw spend data - Test\")\n",
    "def raw_spend_data():\n",
    "  return (spark.readStream.format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\",\"csv\")\n",
    "    .option(\"cloudFiles.schemaHints\", \"id int, age int, annual_income float, spending_core float\")\n",
    "    .load(f\"/Volumes/dbdemos/dbdemos_dlt_unit_test/raw_data/test/spend_csv/*.csv\"))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DLT-ingest_test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

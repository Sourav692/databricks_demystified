{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0fba6bb3-fd75-4308-a73b-241dc3f7f951",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Testing our DLT pipeline\n",
    "\n",
    "Tests can be added directly as expectation within DLT.\n",
    "\n",
    "This is typically done using a companion notebook and creating a test version of the DLT pipeline.\n",
    "\n",
    "The test DLT pipeline will consume a small test datasets that we'll use to perform cheks on the output: given a specific input, we test the transformation logic by ensuring the output is correct, adding wrong data as input to cover all cases.\n",
    "\n",
    "By leveraging expectations, we can simply run a test DLT pipeline. If the pipeline fail, this means that our tests are failing and something is incorrect.\n",
    "\n",
    "<img style=\"float: right\" width=\"1000px\" src=\"https://github.com/QuentinAmbard/databricks-demo/raw/main/product_demos/dlt-advanecd/DLT-advanced-unit-test-3.png\"/>\n",
    "\n",
    "<!-- Collect usage data (view). Remove it to disable collection. View README for more details.  -->\n",
    "<img width=\"1px\" src=\"https://ppxrzfxige.execute-api.us-west-2.amazonaws.com/v1/analytics?category=data-engineering&org_id=3782931733495456&notebook=%2Ftest%2FDLT-Tests&demo_name=dlt-unit-test&event=VIEW&path=%2F_dbdemos%2Fdata-engineering%2Fdlt-unit-test%2Ftest%2FDLT-Tests&version=1&user_hash=f54348b201997908b91ace6288a9864114e7faea0de6a910579a7ab80989b7e0\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0140ce39-dd65-4e9e-ae93-83a6dac14d6a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Testing incorrect schema ingestion\n",
    "\n",
    "The first thing we'd like to test is that our pipeline is robust and will discard incorrect rows.\n",
    "\n",
    "As example, this line from our test dataset should be discarded and flagged as incorrect:\n",
    "```\n",
    "{\"id\":\"invalid ID\", \"email\":\"margaret84@example.com\", ....}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c29f59b5-5022-4e67-b1ed-eccbe1a314f7",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Let's make sure incorrect input rows (bad schema) are dropped"
    }
   },
   "outputs": [],
   "source": [
    "CREATE TEMPORARY LIVE TABLE TEST_user_bronze_dlt (\n",
    "  CONSTRAINT incorrect_data_removed EXPECT (not_empty_rescued_data = 0) ON VIOLATION FAIL UPDATE\n",
    ")\n",
    "COMMENT \"TEST: bronze table properly drops row with incorrect schema\"\n",
    "AS SELECT count(*) as not_empty_rescued_data from live.user_bronze_dlt  where _rescued_data is not null or email='margaret84@example.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6ab73fc-95bb-461a-a7f3-ee897486040f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Let's continue our tests on the silver table with multiple checks at once\n",
    "\n",
    "We'll next ensure that our silver table transformation does the following:\n",
    "\n",
    "* null ids are removed (our test dataset contains null)\n",
    "* we should have 4 rows as output (based on the input)\n",
    "* the emails are properly anonymized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e0cf61e1-47d7-4944-90ce-4536c7c9453f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TEMPORARY LIVE TABLE TEST_user_silver_dlt_anonymize (\n",
    "  CONSTRAINT keep_all_rows              EXPECT (num_rows = 4)      ON VIOLATION FAIL UPDATE, \n",
    "  CONSTRAINT email_should_be_anonymized EXPECT (clear_email = 0)  ON VIOLATION FAIL UPDATE,\n",
    "  CONSTRAINT null_ids_removed           EXPECT (null_id_count = 0) ON VIOLATION FAIL UPDATE  \n",
    ")\n",
    "COMMENT \"TEST: check silver table removes null ids and anonymize emails\"\n",
    "AS (\n",
    "  WITH\n",
    "   rows_test  AS (SELECT count(*) AS num_rows       FROM live.user_silver_dlt),\n",
    "   email_test AS (SELECT count(*) AS clear_email    FROM live.user_silver_dlt  WHERE email LIKE '%@%'),\n",
    "   id_test    AS (SELECT count(*) AS null_id_count  FROM live.user_silver_dlt  WHERE id IS NULL)\n",
    "  SELECT * from email_test, id_test, rows_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6211ef67-b123-40ba-87db-4746ed6c5693",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Testing Primary key uniqueness\n",
    "\n",
    "Finally, we'll enforce uniqueness on the gold table to avoid any duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ca07eaa-36a5-4c4a-b628-4668ec571d49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "CREATE TEMPORARY LIVE TABLE TEST_user_gold_dlt (\n",
    "  CONSTRAINT pk_must_be_unique EXPECT (duplicate = 1) ON VIOLATION FAIL UPDATE\n",
    ")\n",
    "COMMENT \"TEST: check that gold table only contains unique customer id\"\n",
    "AS SELECT count(*) as duplicate, id FROM live.user_gold_dlt GROUP BY id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c454799e-0e9d-44c7-b375-376eb48530db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "That's it. All we have to do now is run the full pipeline.\n",
    "\n",
    "If one of the condition defined in the TEST table fail, the test pipeline expectation will fail and we'll know something need to be fixed!\n",
    "\n",
    "You can open the <a dbdemos-pipeline-id=\"dlt-test\" href=\"#joblist/pipelines/31fac930-f846-41f5-85ac-3ec032abf9a1\">Delta Live Table Pipeline for unit-test</a> to see the tests in action"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "DLT-Tests",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
